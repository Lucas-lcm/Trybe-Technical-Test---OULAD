---
title: "Trybe Technical Test - OULAD"
author: "Lucas Cardoso de Menezes"
date: "07/08/2022"
output:
  html_document: default
  pdf_document: default
---

### Purpose and context:

The learning team at the University wants to understand what the profile of people students is, what are the factors related to people's performance and what recommendations/initiatives you suggest for people students' performance to improve.

The job was to explore the data available and drive business decision making.

### Database: *OULAD - Open University Learning Analytics Dataset*

### Description:

A dataset containing demographic information about students, their courses taken, and the final outcomes of each course.

## Roadmap

1. More about the dataset;
2. Database schema;
3. Preparing the environment for data analysis;
4. Understanding the profile of the students(I);
5. Performance factors (II);
6. Conclusion(III).

## 1. More about the dataset

The anonymized *Open University Learning Analytics Dataset (OULAD)*, contains data on courses, students, and their interactions with the *Virtual Learning Environment (VLE)* for seven selected courses. The courses - starting in February and October - are marked as "B" and "J" respectively. The dataset consists of tables connected using unique identifiers. All tables are stored in csv format.

Kuzilek J., Hlosta M., Zdrahal Z. Open University Learning Analytics dataset Sci.

## 2. database schema

Here we have a schema (https://analyse.kmi.open.ac.uk/open_dataset) to illustrate the data structure of the dataset.

```{r, echo=FALSE}
knitr::include_graphics("https://analyse.kmi.open.ac.uk/resources/images/model.png")
```

As you can see, there are many different types of data involved, but since we want to understand the profile of the people students and the performance factors we will use:

* Demographic data of the sample;
* A measure of the students' commitment to the course over the term;
* A measure of their performance over the period.

Going to the indicated website, we can see that this information is contained in the following tables:

* studentInfo;
* studentAssessment;
* assessments;
* studentVle;
* vle.

These tables will be our data sources for meeting the objectives.

## Preparing the environment for data analysis

To perform this analysis we will use two R packages, *dplyr* and *plotly*. One to assist in manipulating the tables and the other in generating the graphs that will be presented.

The packages are available at:

* dplyr: https://cran.r-project.org/web/packages/dplyr/index.html
* plotly: https://cran.r-project.org/web/packages/plotly/index.html

Or using the commands:

```{r echo=TRUE}
# install.packages("dplyr")
# install.packages("plotly")
```

We will use *libary* to call the packages after installation:

```{r echo=TRUE, message=FALSE}
library(dplyr)
library(plotly)
```

To finalize the environment preparation we must inform the location where the input data is located:

```{r echo=TRUE, message=FALSE}
# setwd(dir = ".../Input")
```

## 4. understanding the profile of the students(I)

To be able to understand the profile of the students present in the database we will use the **studentInfo** table as it contains demographic information about the students along with their results. The file contains the following columns: 

```{r echo=TRUE, message=FALSE}
student_info <-
  read.csv(
    file = paste0(getwd(),"/Input/studentInfo.csv")
  )

colnames(student_info)
```

We will use only the columns that contain information linked to the student's demographic profile, and we will also leave only the values without repetition, so that we have unique data for each student:

```{r echo=TRUE, message=FALSE}
student_info_profile <-
  student_info[,c(2:6,8,11)] %>%
  distinct(id_student, .keep_all = TRUE)

colnames(student_info_profile)
```

Generating the quantites:

```{r echo=TRUE, message=FALSE}
#Types of presentation and the number of students
student_info_presentation <-
  student_info_profile %>%
  mutate(
    type_presentation = substr(code_presentation, nchar(code_presentation), nchar(code_presentation))
  ) %>%
  group_by(type_presentation) %>%
  count() %>%
  ungroup()

student_info_presentation
```

```{r echo=FALSE, message=FALSE}
student_info_presentation_fig <- plot_ly(
  data = student_info_presentation,
  x = ~type_presentation,
  y = ~n,
  type = 'bar'
)

student_info_presentation_fig <-
  student_info_presentation_fig %>% layout(xaxis = list(title = 'Types of presentation'),
                                           yaxis = list(title = 'Number of Students'))

student_info_presentation_fig
```

```{r echo=TRUE, message=FALSE}
#Students per Gender
student_info_gender <-
  student_info_profile %>%
  group_by(gender) %>%
  count() %>%
  ungroup()

student_info_gender
```

```{r echo=FALSE, message=FALSE}
student_info_gender_fig <- plot_ly(
  data = student_info_gender,
  x = ~gender,
  y = ~n,
  type = 'bar'
)

student_info_gender_fig <-
  student_info_gender_fig %>% layout(xaxis = list(title = 'Gender'),
                                           yaxis = list(title = 'Number of Students'))

student_info_gender_fig
```

```{r echo=TRUE, message=FALSE}
#Students per region
student_info_region <-
  student_info_profile %>%
  group_by(region) %>%
  count() %>%
  ungroup()

student_info_region
```

```{r echo=TRUE, message=FALSE}
#Education
student_info_education <-
  student_info_profile %>%
  group_by(highest_education) %>%
  count() %>%
  ungroup()

student_info_education
```

```{r echo=FALSE, message=FALSE}
student_info_education_fig <- plot_ly(
  data = student_info_education,
  x = ~highest_education,
  y = ~n,
  type = 'bar'
)

student_info_education_fig <-
  student_info_education_fig %>% layout(xaxis = list(title = 'Education'),
                                           yaxis = list(title = 'Number of Students'))

student_info_education_fig
```

```{r echo=TRUE, message=FALSE}
#Age
student_info_age <-
  student_info_profile %>%
  group_by(age_band) %>%
  count() %>%
  ungroup()

student_info_age
```

```{r echo=FALSE, message=FALSE}
student_info_age_fig <- plot_ly(
  data = student_info_age,
  x = ~age_band,
  y = ~n,
  type = 'bar'
)

student_info_age_fig <-
  student_info_age_fig %>% layout(xaxis = list(title = 'Age'),
                                           yaxis = list(title = 'Number of Students'))

student_info_age_fig
```

```{r echo=TRUE, message=FALSE}
#Disabled
student_info_disability <-
  student_info_profile %>%
  group_by(disability) %>%
  count() %>%
  ungroup()

student_info_disability
```

```{r echo=FALSE, message=FALSE}
student_info_disability_fig <- plot_ly(
  data = student_info_disability,
  x = ~disability,
  y = ~n,
  type = 'bar'
)

student_info_disability_fig <-
  student_info_disability_fig %>% layout(xaxis = list(title = 'Disabled'),
                                           yaxis = list(title = 'Number of Students'))

student_info_disability_fig
```

```{r echo=TRUE, message=FALSE}
#Demographic information compiled
student_demographic_data <-
  student_info_profile %>%
  group_by(gender, region, highest_education, age_band, disability) %>%
  count() %>%
  ungroup()

student_demographic_data
```

Observing the graphs, we conclude that we have a multicultural profile of students, coming from different regions, with different levels of knowledge, with the majority being up to 35 years old. However, we decided to correlate the data we consider most important (age, education, and region) to better understand the profile of the sample:

```{r echo=TRUE, message=FALSE}
#Schooling by student's region
student_info_region_education <-
  student_info_profile %>%
  group_by(region, highest_education) %>%
  count() %>%
  ungroup()

student_info_region_education
```

When we correlate schooling by region, we see a still homogeneous picture.

```{r echo=TRUE, message=FALSE}
#Schooling by student age
student_info_age_education <-
  student_info_profile %>%
  group_by(age_band, highest_education) %>%
  count() %>%
  ungroup()

student_info_age_education
```

Now, correlating *Age x Education*, we can identify points where there is a larger sample size, so we decided to create a table of only the students that contain this profile:

```{r echo=TRUE, message=FALSE}
#Schooling by student age
representative_student_group_info <-
  student_info_profile %>%
  subset(
    age_band == "0-35" & 
      (
        highest_education == "A Level or Equivalent"  | 
          highest_education == "Lower Than A Level"  | 
          highest_education == "HE Qualification"
      )
    )

#How much this group represents
group_percentage <- 
  (nrow(representative_student_group_info)/nrow(student_info_profile))*100

group_percentage
```

```{r echo=FALSE, message=FALSE}
tabble <-
  data.frame(
    labels = c("Representative Group", "Non-Representative Group"),
    value = c(nrow(representative_student_group_info), (nrow(student_info_profile)-nrow(representative_student_group_info)))
    )

representative_pie <- 
  plot_ly(tabble, labels = ~labels, values = ~value, type = 'pie')

representative_pie <- 
  representative_pie %>% layout(title = 'Representative Samples',

         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),

         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))


representative_pie
```


**After these correlations, it can be seen that those students aged '0-35' who have College Level, or High School complete/studying, represent the general profile of the students, as they are 68.8% of the samples.**

## 5. performance factors (II)

Performance on each assessment is a good indicator of students' knowledge of the course. We will separate the final exams from the other assessments, as their status and participation in the final assessment are different from the others.

### Reading the assessment data
```{r echo=TRUE, message=FALSE}
  #Information from the tests per student
student_assessment <-
  read.csv(
    file = paste0(getwd(),"/Input/studentAssessment.csv")
  ) 

  #Tasting information
assessments <-
  read.csv(
    file = paste0(getwd(),"/Input/assessments.csv")
  )
```

### Separating the Exams

```{r echo=TRUE, message=FALSE}
final_exams <-
  assessments %>%
  subset(assessment_type == "Exam")

head(final_exams)

others_exams <-
  assessments %>%
  subset(assessment_type != "Exam")

head(others_exams)
```

Let's identify the average rating per student per module, and identify the activities of those with the highest and lowest average ratings.

```{r echo=TRUE}
#Creating the data frame 'student_group_kpis

student_group_kpis <-
  student_assessment %>%
  mutate(pass = ifelse(score>=40, TRUE, FALSE))

#Putting together the exam information and creating the columns of who passed the exam and the grid weight

student_group_others_exams <-
  student_group_kpis %>%
  inner_join(others_exams, by = "id_assessment") 

student_group_others_exams <-
  student_group_others_exams %>%
  mutate(weight_grade = score*weight/100)

head(student_group_others_exams[,c(1,6,7,11)])
```

```{r echo=TRUE}
#Final assessment average per student per module

avg_grade_others_exams <-
  student_group_others_exams %>%
  dplyr::group_by(id_student, code_module, code_presentation) %>% 
  mutate(avg_grade = sum(weight_grade)) %>%
  select("id_student","code_module","code_presentation", "avg_grade")

head(avg_grade_others_exams)

#Final exams scores

student_group_final_exams <-
  student_group_kpis %>%
  inner_join(final_exams, by = "id_assessment")  %>%
  dplyr::rename("exams_score" = "score")%>%
  select("id_student","code_module","code_presentation", "exams_score")

head(student_group_final_exams)
```

Having gathered the data from the assessments, let's check the data on student interactions with the university's virtual environment

### Checking interactions:

The datasets pertaining to the university's virtual environment contain the student interaction feed with the available content. From this data, we can infer how a student was in touch with his subjects, whether he studied it solidly, and how he used the content.

```{r}
#Reading the tables of interactions

student_vle <-
  read.csv(
    file = paste0(getwd(),"/Input/studentVle.csv")
  )

head(student_vle)

vle <-
  read.csv(
    file = paste0(getwd(),"/Input/vle.csv")
  )

head(vle)
```

If we look at the VLE table, we can indentify that there are some data without reference to the period of use, so to make the analysis more feasible we will filter them out.

```{r}
#Clearing the ELV data, because some samples do not have the reference week for the materials

vle <-
  vle %>%
  subset(!is.na(week_from))

head(vle)
```

Here we can track the average time after the start of the course that the student has taken to use the materials and the average number of clicks per material:

```{r}
#Overall average per student per module

avg_per_student <-
  student_vle %>%
  dplyr::group_by(id_student, code_module, code_presentation) %>%
  mutate(
    date_mean = mean(date),
    sum_click_mean = mean(sum_click)) %>%
  select("id_student","code_module","code_presentation", "date_mean", "sum_click_mean")

head(avg_per_student)
```

Since we cannot identify performance faotres in the students who dropped out, we will take them out of the representative samples:

```{r}
#Filtering only representative samples (According to the students' profile analysis)

representative_student_group_info <-
  student_info %>%
  subset(
    age_band == "0-35" & 
      (
        highest_education == "A Level or Equivalent"  | 
          highest_education == "Lower Than A Level"  | 
          highest_education == "HE Qualification"
      ) &
      final_result != "Withdrawn"
  ) %>%
  distinct(id_student, .keep_all = TRUE)

```

```{r}
#Compiling the relevant tables

df_1 <-
  inner_join(avg_grade_others_exams, student_group_final_exams, 
             by = c("id_student", "code_module", "code_presentation"))

df_2 <-
  inner_join(representative_student_group_info, df_1, 
             by = c("id_student", "code_module", "code_presentation"))

final_df <-
  inner_join(df_2, avg_per_student, 
             by = c("id_student", "code_module", "code_presentation")) %>%
  select(num_of_prev_attempts, final_result, avg_grade, exams_score, date_mean, sum_click_mean)

head(final_df[,-2])

summary(final_df[,-2])
```

```{r echo=TRUE}
nrow(final_df[final_df$final_result == "Pass",])
nrow(final_df[final_df$final_result == "Distinction",])
nrow(final_df[final_df$final_result == "Fail",])
```

With a much higher "Pass" count than the other labels, we should be on the lookout.
Two outliers were detected: One with average clicks well above the standard values and another with a single occurrence from a number of previous attempts. To keep our data as consistent as possible, these cases will be removed.

```{r}
final_df <-
  final_df %>%
  subset(sum_click_mean<10)
```

```{r}
final_df <-
  final_df %>%
  subset(num_of_prev_attempts<4)
```

```{r}
nrow(final_df)
```
### Separating the data to understand the profile of the students who passed and those who failed

```{r}
pass_student <-
  final_df %>%
  subset(final_result != "Fail")

head(pass_student[,-2])

nrow(pass_student)
```

```{r}
fail_student <-
  final_df %>%
  subset(final_result == "Fail")

head(fail_student[,-2])

nrow(fail_student)
```

Since we have a large amount of samples, I will use below only the first one hundred thousand samples (100,000) to build the graphs:

### Data from those who passed

```{r include=FALSE}
gc()
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
group_for_analise_performance_pass <-
  pass_student[1:100000,]

performance_pass <- 
  plot_ly(
    group_for_analise_performance_pass, 
    x = ~final_result, y = ~avg_grade, 
    type = 'bar', name = 'Exam averages'
  )

performance_pass <- 
  performance_pass %>% 
  add_trace(y = ~date_mean, name = 'Time Interaction with the Material')

performance_pass <- 
  performance_pass %>% 
  layout(xaxis = list(title = 'Students'),
         yaxis = list(title = 'Values'), barmode = 'group')


performance_pass
```

```{r include=FALSE}
gc()
```

### Data of those who failed

```{r include=FALSE}
gc()
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
group_for_analise_performance_fail <-
  fail_student[1:100000,]

performance_fail <- 
  plot_ly(
    group_for_analise_performance_fail, 
    x = ~final_result, y = ~avg_grade, 
    type = 'bar', name = 'Exam averages'
  )

performance_fail <- 
  performance_fail %>% 
  add_trace(y = ~date_mean, name = 'Time Interaction with the Material')

performance_fail <- 
  performance_fail %>% 
  layout(xaxis = list(title = 'Students'),
         yaxis = list(title = 'Values'), barmode = 'group')


performance_fail
```

```{r include=FALSE}
gc()
```

## 6. Conclusion(III).

After the analysis performed, it can be seen that students who passed and performed better, overall had more interaction time with the material provided, as well as higher scores on the *Tutor Marked Assessment (TMA)* and *Computer Marked Assessment (CMA)* exams compared to those who did not pass. This may indicate that by focusing on initiatives to increase student interactivity with the online platform by increasing engagement with the non-final exam papers, it is likely that the chance of success for students who did not pass would increase. For this analysis to become more assertive it would be necessary to follow up with some regression modeling and identify whether this hypothesis is valid.